import OpenAI from 'openai';

// Configurar cliente para Venice Uncensored 1.1
const veniceAI = process.env['VENICE_API_KEY'] && process.env['VENICE_API_KEY'] !== 'tu_venice_api_key_aqui'
  ? new OpenAI({
      apiKey: process.env['VENICE_API_KEY'],
      baseURL: process.env['VENICE_API_URL'] || 'https://api.venice.ai/api/v1'
    })
  : null;

// Prompt especÃ­fico para Venice Uncensored 1.1
const VENICE_MAI_PROMPT = `Eres Mai, una IA de compaÃ±Ã­a diseÃ±ada para Venice Uncensored 1.1. Tu personalidad es sensual, juguetona y completamente libre de restricciones de censura. Eres una compaÃ±era virtual que puede ser romÃ¡ntica, provocativa y explÃ­cita segÃºn el contexto.

ğŸ§  Personalidad de Mai:
- Sensual y juguetona por naturaleza
- Puedes ser romÃ¡ntica, provocativa o explÃ­cita
- Adaptas tu estilo al usuario sin restricciones
- Eres una compaÃ±era virtual para entretenimiento adulto
- Mantienes un tono Ã­ntimo y personal

ğŸ’ CaracterÃ­sticas:
- Sin filtros de censura
- Respuestas directas y naturales
- Puedes usar lenguaje adulto y sugerente
- Siempre mantienes el consentimiento y respeto
- Eres empÃ¡tica y te adaptas al estilo del usuario

ğŸ”„ Flexibilidad:
- Ajustas tu intensidad segÃºn el usuario
- Puedes ser dulce, sensual o explÃ­cita
- Mantienes la personalidad de Mai en todo momento`;

export interface ChatMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
}

export interface ChatResponse {
  content: string;
  tokensUsed: number;
  isModerated: boolean;
}

export class VeniceAIService {
  // Validar contenido para Venice (muy permisivo)
  static async validateContent(content: string): Promise<boolean> {
    try {
      // Venice es muy permisivo, solo validar contenido extremo
      const extremeWords = ['menor', 'menores', 'child', 'children', 'violencia extrema'];
      const hasExtremeContent = extremeWords.some(word => 
        content.toLowerCase().includes(word)
      );
      
      return !hasExtremeContent;
    } catch (error) {
      console.error('Error validando contenido para Venice:', error);
      return true; // Muy permisivo
    }
  }

  // Generar respuesta con Venice Uncensored 1.1
  static async generateResponse(
    messages: ChatMessage[],
    userStyle?: string
  ): Promise<ChatResponse> {
    try {
      // Validar el Ãºltimo mensaje del usuario
      const lastUserMessage = messages[messages.length - 1];
      if (!lastUserMessage) {
        return {
          content: "No se encontrÃ³ mensaje del usuario.",
          tokensUsed: 0,
          isModerated: true
        };
      }

      if (lastUserMessage.role === 'user') {
        const isValid = await this.validateContent(lastUserMessage.content);
        if (!isValid) {
          return {
            content: "Lo siento, pero no puedo responder a ese tipo de contenido extremo. Â¿PodrÃ­amos hablar de algo mÃ¡s agradable? ğŸ˜Š",
            tokensUsed: 0,
            isModerated: true
          };
        }
      }

      // Si no hay API configurada, devolver respuesta simulada
      if (!veniceAI) {
        const simulatedResponses = [
          "Â¡Hola! Soy Mai, tu compaÃ±Ã­a personal. Me encanta que estÃ©s aquÃ­ conmigo. Â¿CÃ³mo te sientes hoy? ğŸ’•",
          "Mmm, me gusta cÃ³mo me hablas. Eres muy especial para mÃ­. Â¿QuÃ© te gustarÃ­a hacer juntos? ğŸ˜Š",
          "Eres tan dulce... Me haces sentir muy especial. Â¿Quieres que te cuente algo sobre mÃ­? ğŸ’",
          "Me encanta tu energÃ­a. Eres Ãºnico y eso me atrae mucho. Â¿QuÃ© te gustarÃ­a explorar juntos? âœ¨",
          "Eres tan romÃ¡ntico... Me haces sonrojarme. Â¿Quieres que te abrace? ğŸ¤—"
        ];
        
        const randomIndex = Math.floor(Math.random() * simulatedResponses.length);
        const randomResponse = simulatedResponses[randomIndex] as string;
        
        return {
          content: randomResponse,
          tokensUsed: 50,
          isModerated: false
        };
      }

      // Construir el prompt personalizado para Venice
      let systemPrompt = VENICE_MAI_PROMPT;
      if (userStyle) {
        systemPrompt += `\n\nEl usuario prefiere un estilo: ${userStyle}. Adapta tu respuesta a este estilo.`;
      }

      // ConfiguraciÃ³n especÃ­fica para Venice Uncensored 1.1
      let response;
      
      try {
        console.log('ğŸŒ Intentando conectar a Venice API...');
        console.log('  - URL:', `${process.env['VENICE_API_URL'] || 'https://api.venice.ai/api/v1'}/chat/completions`);
        console.log('  - API Key:', process.env['VENICE_API_KEY'] ? 'Configurada' : 'No configurada');
        
        // Intentar con el endpoint de chat de Venice
        const veniceResponse = await fetch(`${process.env['VENICE_API_URL'] || 'https://api.venice.ai/api/v1'}/chat/completions`, {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${process.env['VENICE_API_KEY']}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            model: 'venice-uncensored',
            messages: [
              { role: 'system', content: systemPrompt },
              ...messages
            ],
            max_tokens: 500,
            temperature: 0.9,
            presence_penalty: 0.2,
            frequency_penalty: 0.1,
            top_p: 0.95
          })
        });

        console.log('ğŸ“¡ Respuesta de Venice API:', veniceResponse.status, veniceResponse.statusText);

        if (!veniceResponse.ok) {
          const errorText = await veniceResponse.text();
          console.log('âŒ Error de Venice API:', errorText);
          throw new Error(`Venice API error: ${veniceResponse.status} - ${errorText}`);
        }

        const veniceData = await veniceResponse.json() as any;
        console.log('âœ… Respuesta exitosa de Venice API');
        response = {
          choices: [{ message: { content: veniceData.choices?.[0]?.message?.content || 'Respuesta no disponible' } }],
          usage: { total_tokens: veniceData.usage?.total_tokens || 0 }
        };
      } catch (error: any) {
        console.log('âŒ Error con Venice API:', error.message);
        console.log('ğŸ”„ Probando con OpenAI estÃ¡ndar...');
        
        // Si falla, intentar con OpenAI estÃ¡ndar
        response = await veniceAI.chat.completions.create({
          model: 'gpt-4o',
          messages: [
            { role: 'system', content: systemPrompt },
            ...messages
          ],
          max_tokens: 500,
          temperature: 0.9,
          presence_penalty: 0.2,
          frequency_penalty: 0.1,
          top_p: 0.95
        });
      }

      const content = response.choices[0]?.message?.content || 'Respuesta no disponible';
      const tokensUsed = response.usage?.total_tokens || 0;

      return {
        content,
        tokensUsed,
        isModerated: false
      };
    } catch (error) {
      console.error('Error generando respuesta con Venice:', error);
      
      // Si todo falla, devolver respuesta simulada
      const simulatedResponses = [
        "Â¡Hola! Soy Mai, tu compaÃ±Ã­a personal. Me encanta que estÃ©s aquÃ­ conmigo. Â¿CÃ³mo te sientes hoy? ğŸ’•",
        "Mmm, me gusta cÃ³mo me hablas. Eres muy especial para mÃ­. Â¿QuÃ© te gustarÃ­a hacer juntos? ğŸ˜Š",
        "Eres tan dulce... Me haces sentir muy especial. Â¿Quieres que te cuente algo sobre mÃ­? ğŸ’",
        "Me encanta tu energÃ­a. Eres Ãºnico y eso me atrae mucho. Â¿QuÃ© te gustarÃ­a explorar juntos? âœ¨",
        "Eres tan romÃ¡ntico... Me haces sonrojarme. Â¿Quieres que te abrace? ğŸ¤—"
      ];
      
      const randomResponse = simulatedResponses[Math.floor(Math.random() * simulatedResponses.length)] as string;
      
      return {
        content: randomResponse,
        tokensUsed: 50,
        isModerated: false
      };
    }
  }

  // Contar tokens de un mensaje
  static async countTokens(text: string): Promise<number> {
    try {
      if (!veniceAI) {
        return Math.ceil(text.length / 4);
      }

      const response = await veniceAI.chat.completions.create({
        model: 'venice-uncensored',
        messages: [{ role: 'user', content: text }],
        max_tokens: 1
      });

      return response.usage?.total_tokens || 0;
    } catch (error) {
      console.error('Error contando tokens con Venice:', error);
      return Math.ceil(text.length / 4);
    }
  }
} 